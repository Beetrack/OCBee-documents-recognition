{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "explore OpenCV.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y-eOVXNOMdWA"
      },
      "source": [
        "# Python OpenCV"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8eW7jIzGSf3R"
      },
      "source": [
        "## Required modules"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rt0AG7GG43mA",
        "outputId": "b6495bd5-1719-49cc-b770-c99e3bed2f02"
      },
      "source": [
        "!sudo apt install tesseract-ocr"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "tesseract-ocr is already the newest version (4.00~git2288-10f4998a-2).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 14 not upgraded.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "165ZJ2Kh4Lkg",
        "outputId": "71a850b6-83be-4aa9-d0a2-2b941c020487"
      },
      "source": [
        "!pip install opencv-python pytesseract"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.6/dist-packages (4.1.2.30)\n",
            "Requirement already satisfied: pytesseract in /usr/local/lib/python3.6/dist-packages (0.3.7)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from opencv-python) (1.18.5)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.6/dist-packages (from pytesseract) (7.0.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WxpWC5wa4Tps"
      },
      "source": [
        "# image processing opencv\n",
        "import cv2 \n",
        "import pytesseract\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "# matcher to get similarity\n",
        "from difflib import SequenceMatcher\n",
        "\n",
        "# results\n",
        "from pprint import pprint"
      ],
      "execution_count": 204,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "prZpd2lmZG5J"
      },
      "source": [
        "## Image example importation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yZKSJgy0ZLpN",
        "outputId": "d086b6a4-8d34-4203-8c9e-ea1605504053"
      },
      "source": [
        "!curl -L -o \"img1.jpg\" \"https://pbs.twimg.com/media/CZl5VNKWQAAQUfO?format=jpg&name=large\""
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  368k  100  368k    0     0   428k      0 --:--:-- --:--:-- --:--:--  428k\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R7oGTKD6aQQl",
        "outputId": "63e1abf4-3935-475d-ca6d-3f8fb614f455"
      },
      "source": [
        "!curl -L -o \"img2.jpg\" \"https://papagayonews.com/wp-content/uploads/2019/11/DzoMHdAW0AM4nTB.pnglarge-720%C3%97463-Google-Chrome.jpg\""
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 62079  100 62079    0     0   230k      0 --:--:-- --:--:-- --:--:--  230k\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-_vRVSM9bFIQ",
        "outputId": "eba7c070-9ad7-4b61-dc6c-e4ffd6cb0586"
      },
      "source": [
        "!curl -L -o \"img3.jpg\" \"https://scontent.fscl11-2.fna.fbcdn.net/v/t1.0-9/41292282_1812427158834835_5101710936150900736_o.jpg?_nc_cat=107&ccb=2&_nc_sid=110474&_nc_ohc=-ERJ_aU6KqsAX8XR7Hz&_nc_ht=scontent.fscl11-2.fna&oh=ca9ab9c1509a5396447369092ac30c3a&oe=5FFE0294\""
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  203k  100  203k    0     0   215k      0 --:--:-- --:--:-- --:--:--  215k\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bX7Akrn1VY61",
        "outputId": "57791839-e4dc-4b9f-e9be-31636a81dc17"
      },
      "source": [
        "!curl -L -o \"img4.jpg\" \"https://upload.wikimedia.org/wikipedia/commons/f/fe/El_ejemplo_de_Cedula_identidad_Chile_2013.jpg\""
      ],
      "execution_count": 170,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  196k  100  196k    0     0   488k      0 --:--:-- --:--:-- --:--:--  487k\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P_luIrIqVdr1",
        "outputId": "1b000bb2-b2ef-4c5a-df8a-a183ed94a507"
      },
      "source": [
        "!curl -L -o \"img5.jpg\" \"https://pbs.twimg.com/media/Ce9vyi8WQAAVD5s?format=jpg&name=large\""
      ],
      "execution_count": 162,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  336k  100  336k    0     0  1741k      0 --:--:-- --:--:-- --:--:-- 1741k\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tyF6HGkJV3Fl",
        "outputId": "f289a315-79c3-44d0-9135-d790db203ad8"
      },
      "source": [
        "!curl -L -o \"img6.jpg\" \"https://ligaseis.leagueapp.cl/logos/89714b760d43988d85bb04aec3801ceb38654cc7\""
      ],
      "execution_count": 163,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  101k  100  101k    0     0   182k      0 --:--:-- --:--:-- --:--:--  182k\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yYatpD0cSino"
      },
      "source": [
        "## Function definitions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ZsEWcfoCN71"
      },
      "source": [
        "### Image binarizationn"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9KBWmNaiITct"
      },
      "source": [
        "def similar(a, b):\n",
        "    return SequenceMatcher(None, a, b).ratio()\n",
        "\n",
        "def similarity_tester(expected, processed, threshold=0.8):\n",
        "    # split processed result and partialy clean it\n",
        "    processed = filter(lambda text: text != '', processed.split('\\n'))\n",
        "    processed = list(map(lambda text: text.replace('\\'', '').strip(), processed))\n",
        "    \n",
        "    matches = []\n",
        "    # comparison is O(n^2) as we do not know the order of the the recieved input\n",
        "    for prc in processed:\n",
        "        for xpct in expected:\n",
        "          thrsh = similar(xpct, prc)\n",
        "          if thrsh >= threshold:\n",
        "              matches.append((xpct, prc, thrsh))\n",
        "\n",
        "    return matches"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JO9xFYzd8YPc"
      },
      "source": [
        "def process_black_white(img_name, threshold=100, contrast=1, brightness=0, show=False):\n",
        "    '''\n",
        "    @params\n",
        "\n",
        "    img_name: str\n",
        "    threshold: int (0-255) -> value of max light of pixel to convert to white\n",
        "    contrast: float (0-3) -> value of desired contrast (1 is no extra applied)\n",
        "    brightness: float (0-100) -> value of extra brightness to apply\n",
        "    show: bool -> show or not image and corresponding percieved text\n",
        "\n",
        "\n",
        "    @returns\n",
        "    \n",
        "    str: percieved read text\n",
        "    '''\n",
        "    img = cv2.imread(img_name)\n",
        "    img = cv2.convertScaleAbs(img, alpha=contrast, beta=brightness)\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    thresh, new_img = cv2.threshold(img, threshold, 255, cv2.THRESH_BINARY)\n",
        "\n",
        "    if show:\n",
        "      print(pytesseract.image_to_string(new_img))\n",
        "      cv2_imshow(new_img)\n",
        "\n",
        "    return pytesseract.image_to_string(new_img)"
      ],
      "execution_count": 156,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TOvveSe2CQLp"
      },
      "source": [
        "### Robust Locally-Adaptive Soft Binarization\n",
        "\n",
        "Ref: https://stackoverflow.com/a/57103789"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VvQnbikgDNHR"
      },
      "source": [
        "def adjust_gamma(image, gamma=1.2):\n",
        "    # build a lookup table mapping the pixel values [0, 255] to\n",
        "    # their adjusted gamma values\n",
        "    invGamma = 1.0 / gamma\n",
        "    table = np.array([((i / 255.0) ** invGamma) * 255\n",
        "        for i in np.arange(0, 256)]).astype(\"uint8\")\n",
        "\n",
        "    # apply gamma correction using the lookup table\n",
        "    return cv2.LUT(image, table)"
      ],
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VzEPZ4COD7JX"
      },
      "source": [
        "# These are probably the only important parameters in the\n",
        "# whole pipeline (steps 0 through 3).\n",
        "BLOCK_SIZE = 40\n",
        "DELTA = 25\n",
        "\n",
        "# Do the necessary noise cleaning and other stuffs.\n",
        "# I just do a simple blurring here but you can optionally\n",
        "# add more stuffs.\n",
        "def preprocess(image):\n",
        "    image = cv2.medianBlur(image, 3)\n",
        "    return 255 - image\n",
        "\n",
        "# Again, this step is fully optional and you can even keep\n",
        "# the body empty. I just did some opening. The algorithm is\n",
        "# pretty robust, so this stuff won't affect much.\n",
        "def postprocess(image):\n",
        "    kernel = np.ones((3,3), np.uint8)\n",
        "    image = cv2.morphologyEx(image, cv2.MORPH_OPEN, kernel)\n",
        "    return image\n",
        "\n",
        "# Just a helper function that generates box coordinates\n",
        "def get_block_index(image_shape, yx, block_size): \n",
        "    y = np.arange(max(0, yx[0]-block_size), min(image_shape[0], yx[0]+block_size))\n",
        "    x = np.arange(max(0, yx[1]-block_size), min(image_shape[1], yx[1]+block_size))\n",
        "    return np.meshgrid(y, x)\n",
        "\n",
        "# Here is where the trick begins. We perform binarization from the \n",
        "# median value locally (the img_in is actually a slice of the image). \n",
        "# Here, following assumptions are held:\n",
        "#   1.  The majority of pixels in the slice is background\n",
        "#   2.  The median value of the intensity histogram probably\n",
        "#       belongs to the background. We allow a soft margin DELTA\n",
        "#       to account for any irregularities.\n",
        "#   3.  We need to keep everything other than the background.\n",
        "#\n",
        "# We also do simple morphological operations here. It was just\n",
        "# something that I empirically found to be \"useful\", but I assume\n",
        "# this is pretty robust across different datasets.\n",
        "def adaptive_median_threshold(img_in, delta):\n",
        "    med = np.median(img_in)\n",
        "    img_out = np.zeros_like(img_in)\n",
        "    img_out[img_in - med < delta] = 255\n",
        "    kernel = np.ones((3,3),np.uint8)\n",
        "    img_out = 255 - cv2.dilate(255 - img_out,kernel,iterations = 2)\n",
        "    return img_out\n",
        "\n",
        "# This function just divides the image into local regions (blocks),\n",
        "# and perform the `adaptive_mean_threshold(...)` function to each\n",
        "# of the regions.\n",
        "def block_image_process(image, block_size, delta):\n",
        "    out_image = np.zeros_like(image)\n",
        "    for row in range(0, image.shape[0], block_size):\n",
        "        for col in range(0, image.shape[1], block_size):\n",
        "            idx = (row, col)\n",
        "            block_idx = get_block_index(image.shape, idx, block_size)\n",
        "            out_image[block_idx] = adaptive_median_threshold(image[block_idx], delta)\n",
        "    return out_image\n",
        "\n",
        "# This function invokes the whole pipeline of Step 2.\n",
        "def process_image(img, block_size=40, delta=25):\n",
        "    image_in = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "    image_in = preprocess(image_in)\n",
        "    image_out = block_image_process(image_in, block_size, delta)\n",
        "    image_out = postprocess(image_out)\n",
        "    return image_out"
      ],
      "execution_count": 139,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FUn3mAQVD-Eh"
      },
      "source": [
        "# This is the function used for composing\n",
        "def sigmoid(x, orig, rad):\n",
        "    k = np.exp((x - orig) * 5 / rad)\n",
        "    return k / (k + 1.)\n",
        "\n",
        "# Here, we combine the local blocks. A bit lengthy, so please\n",
        "# follow the local comments.\n",
        "def combine_block(img_in, mask):\n",
        "    # First, we pre-fill the masked region of img_out to white\n",
        "    # (i.e. background). The mask is retrieved from previous section.\n",
        "    img_out = np.zeros_like(img_in)\n",
        "    img_out[mask == 255] = 255\n",
        "    fimg_in = img_in.astype(np.float32)\n",
        "\n",
        "    # Then, we store the foreground (letters written with ink)\n",
        "    # in the `idx` array. If there are none (i.e. just background),\n",
        "    # we move on to the next block.\n",
        "    idx = np.where(mask == 0)\n",
        "    if idx[0].shape[0] == 0:\n",
        "        img_out[idx] = img_in[idx]\n",
        "        return img_out\n",
        "\n",
        "    # We find the intensity range of our pixels in this local part\n",
        "    # and clip the image block to that range, locally.\n",
        "    lo = fimg_in[idx].min()\n",
        "    hi = fimg_in[idx].max()\n",
        "    v = fimg_in[idx] - lo\n",
        "    r = hi - lo\n",
        "\n",
        "    # Now we use good old OTSU binarization to get a rough estimation\n",
        "    # of foreground and background regions.\n",
        "    img_in_idx = img_in[idx]\n",
        "    ret3,th3 = cv2.threshold(img_in[idx],0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
        "\n",
        "    # Then we normalize the stuffs and apply sigmoid to gradually\n",
        "    # combine the stuffs.\n",
        "    bound_value = np.min(img_in_idx[th3[:, 0] == 255])\n",
        "    bound_value = (bound_value - lo) / (r + 1e-5)\n",
        "    f = (v / (r + 1e-5))\n",
        "    f = sigmoid(f, bound_value + 0.05, 0.2)\n",
        "\n",
        "    # Finally, we re-normalize the result to the range [0..255]\n",
        "    img_out[idx] = (255. * f).astype(np.uint8)\n",
        "    return img_out\n",
        "\n",
        "# We do the combination routine on local blocks, so that the scaling\n",
        "# parameters of Sigmoid function can be adjusted to local setting\n",
        "def combine_block_image_process(image, mask, block_size):\n",
        "    out_image = np.zeros_like(image)\n",
        "    for row in range(0, image.shape[0], block_size):\n",
        "        for col in range(0, image.shape[1], block_size):\n",
        "            idx = (row, col)\n",
        "            block_idx = get_block_index(image.shape, idx, block_size)\n",
        "            out_image[block_idx] = combine_block(\n",
        "                image[block_idx], mask[block_idx])\n",
        "    return out_image\n",
        "\n",
        "# Postprocessing (should be robust even without it, but I recommend\n",
        "# you to play around a bit and find what works best for your data.\n",
        "# I just left it blank.\n",
        "def combine_postprocess(image):\n",
        "    return image\n",
        "\n",
        "# The main function of this section. Executes the whole pipeline.\n",
        "def combine_process(img, mask):\n",
        "    image_in = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "    image_out = combine_block_image_process(image_in, mask, 20)\n",
        "    image_out = combine_postprocess(image_out)\n",
        "    return image_out"
      ],
      "execution_count": 140,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UtQ3ubdjIyha"
      },
      "source": [
        "# pipelining previous code to return the final image with text\n",
        "\n",
        "def process_locall_adjusted(img_name, gamma=1, block_size=40, delta=25, show=False):\n",
        "    img = cv2.imread(img_name)\n",
        "    mask = adjust_gamma(img, gamma=gamma)\n",
        "    mask = process_image(mask, block_size=block_size, delta=delta)\n",
        "    new_img = combine_process(img, mask)\n",
        "\n",
        "    if show:\n",
        "      print(pytesseract.image_to_string(new_img))\n",
        "      cv2_imshow(new_img)\n",
        "\n",
        "    return pytesseract.image_to_string(new_img) "
      ],
      "execution_count": 141,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "00DNANGkLh2k"
      },
      "source": [
        "## Results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2UqK36agZ9Tv"
      },
      "source": [
        "**Disclaimer**: all images were publicly found on Google images search and are references in the beginning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k4GAYT2TYpQL"
      },
      "source": [
        "expected = [\n",
        "  ['RODRIGUEZ', 'ZEPEDA', 'CLAUDIO ANTONIO', 'CHILENA M', '13 OCT 1965 102.814.050', '05 AGO 2014 13 OCT 2019', 'RUN 9.932.656-5'],\n",
        "  ['RODRIGUEZ', 'APONTE', 'MARIA TERESA', 'EXTRANJERO', 'VEN F', '15 MAR 1991', '06 SEPT 2018 31 AGO 2019'],\n",
        "  ['SANHUEZA', 'HARRIS', 'OLGA ESTER', 'CHILENA M', '25 SEPT 1964', '23 JUL 2014'],\n",
        "  ['FRERDEZ', 'VIDAL', 'MARCELA CAROLINA', 'CHILENA F', '21 FEB 1982 100000001', '1 SEP 2013 10 AGO 2023', 'RUN 12.749.625-K'],\n",
        "  ['MALDONADO', 'JEREZ', 'JUANN DANIEL', '15 MAR 1948 102.773.350', '31 JUL 2014 15 MAR 2020', 'RUN 5.632.605-7'],\n",
        "  ['LEIVA', 'SEREY', 'RONY ORLANDO', 'CHILENA M', '31 DIC 1997 511.408.104', '13 MAR 2017 31 DIC 2020', 'RUN 19.711.416-9']\n",
        "]"
      ],
      "execution_count": 215,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yUzn2mqHHSI7"
      },
      "source": [
        "### Simple B&W"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L76axHu-OhQS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "008fdc3b-2458-4308-a447-b2519f1dc888"
      },
      "source": [
        "import warnings\n",
        "# ignore specific warning of Colab\n",
        "warnings.filterwarnings(action='ignore')\n",
        "\n",
        "print('Simple B&W\\n')\n",
        "for i in range(1, 7):\n",
        "    result = process_black_white('img{}.jpg'.format(i), threshold=100, show=False)\n",
        "    result = similarity_tester(expected[i - 1], result)\n",
        "    print('detected {}%'.format( (len(result) / len(expected[i - 1])) * 100 ))\n",
        "\n",
        "print('\\nAdaptive\\n')\n",
        "for i in range(1, 7):\n",
        "    result = process_locall_adjusted('img{}.jpg'.format(i), block_size=80, delta=50, show=False)\n",
        "    result = similarity_tester(expected[i - 1], result)\n",
        "    print('detected {}%'.format( (len(result) / len(expected[i - 1])) * 100 ))"
      ],
      "execution_count": 230,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Simple B&W\n",
            "\n",
            "detected 100.0%\n",
            "detected 100.0%\n",
            "detected 100.0%\n",
            "detected 42.857142857142854%\n",
            "detected 33.33333333333333%\n",
            "detected 100.0%\n",
            "\n",
            "Adaptive\n",
            "\n",
            "detected 100.0%\n",
            "detected 100.0%\n",
            "detected 83.33333333333334%\n",
            "detected 100.0%\n",
            "detected 100.0%\n",
            "detected 100.0%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H31ZiFYazNOp"
      },
      "source": [
        "## Performance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GqaJYCn6WrNz",
        "outputId": "654e14ff-a73c-4347-dd33-1f4dc7765531"
      },
      "source": [
        "print('Simple B&W\\n')\n",
        "for i in range(1, 7):\n",
        "    %timeit process_black_white('img{}.jpg'.format(i), threshold=100, show=False)\n",
        "\n",
        "print('\\nAdaptive\\n')\n",
        "for i in range(1, 7):\n",
        "    %timeit process_locall_adjusted('img{}.jpg'.format(i), block_size=80, delta=50, show=False)"
      ],
      "execution_count": 231,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Simple B&W\n",
            "\n",
            "1 loop, best of 3: 1.24 s per loop\n",
            "1 loop, best of 3: 955 ms per loop\n",
            "1 loop, best of 3: 927 ms per loop\n",
            "1 loop, best of 3: 588 ms per loop\n",
            "1 loop, best of 3: 1 s per loop\n",
            "1 loop, best of 3: 1.34 s per loop\n",
            "\n",
            "Adaptive\n",
            "\n",
            "1 loop, best of 3: 3.08 s per loop\n",
            "1 loop, best of 3: 1.08 s per loop\n",
            "1 loop, best of 3: 1.96 s per loop\n",
            "1 loop, best of 3: 924 ms per loop\n",
            "1 loop, best of 3: 3.11 s per loop\n",
            "1 loop, best of 3: 1.82 s per loop\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}